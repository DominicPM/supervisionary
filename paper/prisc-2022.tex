\documentclass[sigplan, review]{acmart}
\settopmatter{printfolios=true, printccs=false, printacmref=false}

\usepackage{prooftree}

\newcommand{\deffont}[1]{\textbf{#1}}
\newcommand{\fall}[1]{\forall{#1}.}
\newcommand{\lam}[1]{\lambda{#1}.}
\newcommand{\rulefont}[1]{(\ensuremath{\mathbf{#1}})}

\bibliographystyle{ACM-Reference-Format}

\setcopyright{none}

\title{The Supervisionary proof-checking kernel}
\subtitle{Or: a work-in-progress toward proof-generating code}

\author{Dominic P. Mulligan}
\orcid{}
\affiliation{
  \institution{Systems Research Group, Arm Research}
  \streetaddress{Fulbourn Road}
  \city{Cambridge}
  \country{United Kingdom}
}
\email{dominic.mulligan@arm.com}

\author{Nick Spinale}
\orcid{}
\affiliation{
  \institution{Systems Research Group, Arm Research}
  \streetaddress{Fulbourn Road}
  \city{Cambridge}
  \country{United Kingdom}
}
\email{nick.spinale@arm.com}

\begin{document}

\maketitle

\paragraph{Some scene setting}

Interactive theorem proving software is typically designed around a trusted proof-checking \emph{kernel}.
The kernel is the sole system component capable of authenticating theorems.
Untrusted automation procedures reside outside of the kernel, and drive it to deduce new theorems via a defined API.
This strategy---first introduced by Milner in his LCF proof assistant---is a reliability mechanism, aiming to ensure that any purported theorem produced by the system is indeed a theorem of the logic.

Switching focus, operating systems are also typically designed around a trusted \emph{kernel}, a privileged component responsible for---amongst other things---mediating interaction betwixt user-space software and hardware.
Untrusted processes interact with the system by issuing kernel \emph{system calls} across a hardware privilege boundary.
In this way, the operating system kernel \emph{supervises} user-space processes.

In this abstract, we explore designing proof-checking kernels as \emph{supervisory software}, where separation between kernel and untrusted code is enforced by \emph{privilege}, not programming language type abstraction and modularity.

\paragraph{The Supervisionary system interface}

\emph{Supervisionary} is a proof-checking system for Gordon's HOL, structured as supervisory software.
Supervisionary provides a \emph{system interface} to untrusted code similar to an operating system's system call interface.
We have implemented Supervisionary as a Wasm host, which allows us to rapidly explore the most important ideas.
Moreover, we use Rust as the system's implementation language---an unusual choice, albeit one that entails no risk of system unsoundness, providing the kernel's system call interface is carefully designed.

In particular, the kernel manages various private heaps within which \emph{kernel objects} are allocated, corresponding to the paraphenalia of any HOL implementation---type-formers, types, term constants, terms, and theorems---and never directly exposed to untrusted code.
Kernel objects are allocated in response to system calls like:
\begin{displaymath}
\mathtt{Term.Handle.AllocateApplication(left, right, out)}
\end{displaymath}
Here, both $\mathtt{left}$ and $\mathtt{right}$ are \emph{kernel handles}, assumed to point-to allocated terms, whilst $\mathtt{out}$ points-to a buffer in untrusted code's memory.
If neither $\mathtt{left}$ nor $\mathtt{right}$ \emph{dangle}, and the types of their referents match, a fresh handle is generated which points-to a new HOL term application object, with internal pointers to the functional- and argument-terms.
This handle is returned to the caller via the $\mathtt{out}$ pointer.

The manipulation and querying of kernel objects is performed defensively by the kernel itself on behalf of untrusted code.
The kernel is careful to maintain invariants such as the \emph{inductivity} of its heaps, with nodes in the kernel object graph pointing-to allocated objects at all times.

Space constraints prevent us from describing the entire Supervisionary system interface for working with, and on, kernel objects.
However, note that theorems are also constructed in a similar way to terms, inductively building derivation trees.
For example, the HOL symmetry rule is exposed as:
\begin{displaymath}
\mathtt{Theorem.Handle.AllocateSym(pre, out)}
\end{displaymath}
Here, $\mathtt{pre}$ points-to an existing theorem object $\Gamma \vdash r = s$ and after succeeding, passing obvious checks, $\mathtt{out}$ contains a handle that points-to a newly-allocated theorem $\Gamma \vdash s = r$.

Note that one consequence of this style of implementation is the ability to provide concise \emph{specifications} of Supervisionary ABI functions.
Essentially, the Supervisionary kernel is a grand exercise in pointer manipulation, and as such our ABI specifications can be expressed as Hoare Triples, using Separation Logic as our assertion language.
Writing $\mathtt{h} \mapsto_{\mathtt{trm}} \mathtt{Application(l, r)}$ to assert that the handle $\mathtt{h}$ points-to a term application (of the term pointed-to by $l$ to the term pointed-to by $r$), and writing $\mathtt{out} \mapsto \mathtt{b}$ to assert that $\mathtt{out}$ points-to the Boolean value $\mathtt{b}$, we have, for example:
\begin{gather*}
\{ h \mapsto_{\mathtt{trm}} \mathtt{Application(l, r)} \} \\
\mathtt{Term.Handle.IsApplication(h, out)} \\
\{ \mathtt{out} \mapsto \mathtt{True} \}
\end{gather*}
(Here, the triple $\{ P \} C \{ Q \}$ asserts that if the command $C$ executes in a state concordant with $P$ then the command succeeds and produces a state concordant with $Q$.)

We now turn our attention to describing some potential uses of the Supervisionary kernel.
Exploring what follows is still a work-in-progress.

\paragraph{More flexible theorem proving tools}

Immediately, we can re-imagine the implementation of the foundations of familiar theorem proving tools.
For this case, the unpriviledged bulk of the theorem proving system runs inside of a WebAssembly (Wasm) sandbox, supervised by the proof-checking kernel which runs as native code in the process hosting the sandbox.
In the case of a typical LCF-style proof assistant such as HOL4, the entire system could be compiled to Wasm, and the module implementing the kernel could be modified to act as a proxy in front of the Supervisionary kernel outside of the sandbox.
This modification has immediate implications for the reliability and auditability of the system, because the only critical component now isolated from the bulk of the system by a priviledged boundary.

% versus just type system
% even memory corruption vulns in bulk aren't a problem
% next step: polyglot theorem proving software
% another benefit: strong isolation boundaries within your proof: isolate important spec from the large proof

\paragraph{Runtime verification}

Nothing in principle stops us from extending Supervisionary's system interface with facilities for sockets, querying a hierarchical filesystem, and other similar tasks tied to abstractions typically provided by an operating system.
In particular, given our use of Wasm, we could implement the Wasm System Interface---a POSIX-like interface for Wasm---transforming Supervisionary from a programmable proof-checker into a general-purpose virtual machine, capable of supporting a wide range of programs.

\emph{What happens if we blur the lines between Supervisionary's interfaces for system access and proof-checking?}

Untrusted code executing under Supervisionary's supervision could be challenged to prove some theorem each time it wished to open a file on the filesystem, or otherwise perform some side-effect.
These theorems could be correctness or security-related theorems, corresponding to a prevailing \deffont{policy} in force.
Moreover, as Supervisionary is capable of capturing the runtime state of untrusted code, these challenges can be HOL predicates that are functions of the reified runtime state of untrusted code, the kernel, and the arguments, and name of, the invoked system call.

Two predicates of interest are $\lam{k}\lam{u}\lam{s}\top$ and $\lam{k}\lam{u}\lam{s}\bot$.
Here, $\top$ and $\bot$ are truth and falsity, and $k$, $u$, and $s$ the kernel and untrusted code states, and packed system call metadata, reified as HOL data, at the point of invocation of the system call.
One can always prove $\{\} \vdash \top$ and therefore $\lam{k}\lam{u}\lam{s}\top$ represents no restriction, whereas $\{ \} \vdash \bot$ is never provable, absent axioms, with $\lam{k}\lam{u}\lam{s}\bot$ representing a ``closing off'' of a system call.
By making the challenge a function of the system call name and arguments, this closing off can be specific, banning a process from calling a particular system call, or a system call with a particular set of arguments, allowing us to mimic mechanisms like \texttt{seccomp} from Linux.

We can go further: metadata about the behaviour of a running process could be maintained---for example, a record of the system calls invoked by a process, thus far.
This record could be used in forming security or correctness challenges, for example by forcing untrusted code to prove that writes to a socket only ever happen after a read, or reads and writes on sockets satisfy some protocol.
In short, HOL acts as \emph{lingua franca} between kernel and untrusted code, through which arbitrarily complex policies may be expressed.

\deffont{Jailing}, wherein a process voluntarily sheds capabilities, is common in existing operating systems.
This can be captured in Supervisionary by allowing a process to dynamically replace the prevailing policy, $\phi$, with a new policy $\psi$, after proving that $\psi$ is a refinement of $\phi$: $\{\} \vdash \fall{k}\fall{u}\fall{s} \psi\ k\ u\ s \longrightarrow \phi\ k\ u\ s$.
Note that this expresses that the states described by $\psi$ are a subset of those described by $\phi$.

Note that this idea shares some similarities with \deffont{proof carrying code}, wherein binaries are accompanied with (skeleton) proofs of their adherence to some policy, and these proofs checked by the operating system prior to execution.
However, the ideas sketched above generalise this: proofs can be generated dynamically, as the program executes, and could more aptly be called \deffont{proof generating code}.
However, this potential use of Supervisionary also blurs the boundary between static and runtime verification, and is capable of expressing use-cases typical of proof-carrying code.
For example, the operational semantics and instruction decoding functionality of Wasm is clearly embeddable in HOL.
Using this, properties of a program $P$ to be executed under Supervisionary's supervision could be established statically, and registered with the kernel, perhaps interactively by a user or by another program executing before $P$ executes.
This theorem can then be used by $P$ in closing challenges from Supervisionary, issued at runtime.

\end{document}














\iffalse

\paragraph{Some scene setting}

Modern operating systems are used for a wide array of tasks.
We focus on just two: providing a relatively portable abstract machine interface to user-space software, and enforcing system-wide security policies.

Most operating systems are architected around a \deffont{kernel}, the root of all trust within a system, which engages in a grand conspiracy with its host microprocessor to take a monopoly on direct access to the system's hardware and sensitive system configuration options.
%Relative to user-space code, the kernel executes at a high level of \emph{privilege}, using hardware \deffont{exception levels}.
%Hardware ensures that sensitive system configuration features, such as system registers and page tables, may only be modified by software executing at a high level of privilege---in effect, only the kernel itself.
Using this monopoly, the kernel protects its own memory from inadvertent or malicious modification, using paged memory protection, and acts as a ``choke point'' at which security policies are enforced.

%Users-space code wishing to interact with a system resource must do so by interacting with the kernel.

The kernel also offers an abstract machine interface to user-space software, smoothing over the vulgarities of programming against any particular peripheral, say.
Useful abstractions, such as sockets and a filesystem, are also commonly offered.
This interface is largely exposed as \deffont{system calls}, defining an \deffont{application binary interface}, or ABI henceforth, which user-space and kernel must understand to interact.
%Executing a system call forces a \deffont{context switch}, within which the thread of execution enters the kernel.
The result of a system call may be written directly into the memory of the calling code, via a pointer argument, for example.
Note the asymmetry: in theory, the kernel can read and modify all of a user-space program's state.

Code written in any language can make use of services via the kernel ABI.
However, programs and runtimes typically make extensive use of low-level libraries---\texttt{libc} being an exemplar---that provide further abstraction over the raw ABI.

This pattern of interaction between trusted and untrusted code via an ABI, wherein trusted code can read and modify the state of untrusted code, is common.
Hypervisors, the Secure World of Arm TrustZone, and virtual machines (in the Wasm sense) are structured in this way.
We call software designed in this pattern \deffont{supervisory software}.

\paragraph{Supervisionary} is a prototype proof-checking system for Gordon's HOL structured as supervisory software, specifically as a Wasm \deffont{host environment}, which allows us to explore the consequences of the design, without becoming entangled in e.g. a real machine's boot ceremony.
The ideas discussed herein could be applied to a real operating system.

Supervisionary is implemented in Rust which does not pose any risk to the logical soundness of the system providing we expose a well-designed ABI.
The kernel manages various private heaps within which \deffont{kernel objects} are allocated, corresponding to the paraphenalia of any HOL implementation---type-formers, types, term constants, terms, and theorems---and never directly exposed to untrusted code.
Kernel objects are allocated in response to system calls like:
\begin{displaymath}
\mathtt{Term.Handle.AllocateApplication(left, right, out)}
\end{displaymath}
Here, both $\mathtt{left}$ and $\mathtt{right}$ are \deffont{kernel handles}, assumed to point-to allocated terms, whilst $\mathtt{out}$ points-to a buffer in untrusted code's memory.
If neither $\mathtt{left}$ nor $\mathtt{right}$ \deffont{dangle}, and the types of their referents match, a fresh handle is generated which points-to a new HOL term application object, with internal pointers to the functional- and argument-terms.
This handle is returned to the caller via the $\mathtt{out}$ pointer.

Modulo bugs, system calls do not panic, but rather return \deffont{error codes} to signal failure.
If $\mathtt{left}$ or $\mathtt{right}$ above dangle, for example, then a defined code is returned.
These checks---which all system calls perform---ensure that the kernel heaps remain \deffont{inductive}, with nodes in the kernel object graph pointing-to allocated objects at all times, a key invariant.
Moreover, kernel objects are only ever allocated, and \emph{never} deallocated or otherwise modified once created, thus ensuring the meaning of an object remains immutable (though it is possible that some \deffont{garbage collection} could be used).

%To check if a handle points-to a $\lambda$-abstraction, for example, one may use:
%\begin{displaymath}
%\mathtt{Term.Handle.IsLambda(handle, out)}
%\end{displaymath}
%This again returns a defined error code if $\mathtt{handle}$ dangles and otherwise writes $\mathtt{true}$ or $\mathtt{false}$ to $\mathtt{out}$, as appropriate.

The manipulation and querying of kernel objects is performed by the kernel itself on behalf of untrusted code.
Space constraints prevent us from describing the entire Supervisionary ABI for working with, and on, kernel objects.
However, note that theorems are also constructed in a similar way to terms, inductively building derivation trees.
For example, the HOL symmetry rule is exposed as:
\begin{displaymath}
\mathtt{Theorem.Handle.AllocateSym(pre, out)}
\end{displaymath}
Here, $\mathtt{pre}$ points-to an existing theorem object $\Gamma \vdash r = s$ and after succeeding, passing obvious checks, $\mathtt{out}$ contains a handle that points-to a newly-allocated theorem $\Gamma \vdash s = r$.

We have described the \emph{what} of Supervisionary and now turn our attention to the \emph{why}.
This can be approached by examining Supervisionary both as a proof-assistant kernel, and as a programming platform.
What follows is largely speculative, and a work-in-progress.

\paragraph{Reinventing the proof-assistant}

Proof-assistants in the LCF lineage are also architected around a \deffont{kernel}, with ostensibly little in common with operating system kernels.
Examining, one sees that both are tasked with preserving invariants in the face of unbounded interaction with untrusted code.
Moreover, whilst operating system kernels enjoy a monopoly on hardware access, proof-assistant kernels enjoy a monopoly on theorem \deffont{authentication}.
In short, both act as roots of all trust within their domains.
Yet, the two are implemented in different ways, with LCF kernels implemented as libraries in a \deffont{meta-language}, usually a functional language.
Kernel interaction is via an \emph{API}, rather than an ABI.

An immediate consequence of our design is that the meta-language is non-existent.
Rather untrusted code ``driving'' the kernel can be written in any language capable of producing Wasm binary-compatible with our ABI.
Arguably, the \emph{natural} choice for this is now not even functional, given the inherently stateful and pointer-oriented nature of the kernel.

LCF-style interaction is centred around the REPL of the meta-language, or some thin layer built atop, itself started from an operating system shell---a kind of shell within a shell.
Our design allows us to dispense with this middle-man, and develop proofs interactively directly in a shell implemented on top of our kernel.
Moreover our kernel inherently internalises kernel objects, and could therefore make them available to browse as special files within a hierarchical filesystem, as discussed below, in analogy to how Linux exposes its internals as special files---for example, the contents of \texttt{/proc/} and \texttt{/dev/}.
In this way, related material could appear grouped in directories, searched using command-line utilities, or opened by a process for use at runtime.

\paragraph{Runtime monitoring}

Nothing in principle stops us from extending Supervisionary's ABI with facilities for sockets, querying a hierarchical filesystem, and other similar system tasks.
In particular, given our use of Wasm, we could implement the Wasm System Interface---a POSIX-like interface for Wasm---transforming Supervisionary from a programmable proof-checker into a general-purpose virtual machine, capable of supporting a wide range of programs.

\emph{What happens if we blur the lines between Supervisionary's ABIs for system access and proof-checking?}
Untrusted code could be challenged to prove some theorem each time it wished to open a file on the filesystem, or otherwise perform some side-effect.
These theorems could be correctness or security-related theorems, corresponding to a prevailing \deffont{policy} in force.
Moreover, as Supervisionary is capable of capturing the runtime state of untrusted code, these challenges can be HOL predicates that are functions of the reified runtime state of untrusted code, the kernel, and the arguments, and name of, the invoked system call.

Two predicates of interest are $\lam{k}\lam{u}\lam{s}\top$ and $\lam{k}\lam{u}\lam{s}\bot$.
Here, $\top$ and $\bot$ are truth and falsity, and $k$, $u$, and $s$ the kernel and untrusted code states, and packed system call metadata, reified as HOL data, at the point of invocation of the system call.
One can always prove $\{\} \vdash \top$ and therefore $\lam{k}\lam{u}\lam{s}\top$ represents no restriction, whereas $\{ \} \vdash \bot$ is never provable, absent axioms, with $\lam{k}\lam{u}\lam{s}\bot$ representing a closing off of a system call.
By making the challenge a function of the system call name and arguments, this closing off can be specific, banning a process from calling a particular system call, or a system call with a particular set of arguments, allowing us to mimic mechanisms like \texttt{seccomp} from Linux.

We can go further.
Metadata about the behaviour of a running process could be maintained: for example, a trace of the system calls invoked by a process, thus far, and used in forming security or correctness challenges, for example by forcing untrusted code to prove that writes to a socket only ever happen after a read.
Information flow policies could also be captured, for example, by forcing untrusted code to commit to a pure function, $f$, to be computed before reading any files, and later showing that a result corresponds to $f$ applied to the content of a particular input file, thereby independent of the content of any other file.
In short, HOL acts as \emph{lingua franca} between kernel and untrusted code, through which arbitrarily complex policies may be expressed.

\deffont{Jailing}, wherein a process voluntarily sheds capabilities, is common in existing operating systems.
This can be captured in Supervisionary by allowing a process to replace the prevailing policy, $\phi$, with a new policy $\psi$, after proving that $\psi$ is a refinment of $\phi$: $\{\} \vdash \fall{k}\fall{u}\fall{s} \psi\ k\ u\ s \longrightarrow \phi\ k\ u\ s$.
Note that this expresses that the states described by $\psi$ are a subset of those described by $\phi$.

\deffont{Proof carrying code} modified the operating system loader, and endowed binaries with skeleton proofs of adherence to some policy, later reconstructed by the loader prior to execution.
The ideas sketched above are different: proofs are generated dynamically, as the program executes, and more aptly called \deffont{proof generating code}.
Moreover, theorems could be generated statically, offline, and used dynamically:

\paragraph{Lastly, specifications}

Supervisionary is an extended exercise in pointer manipulation.
The semantics of our system calls can therefore be expressed as Hoare Triples, using formulae of \deffont{Separation Logic} as an assertion language.
Write $\mathtt{h} \mapsto_{\mathtt{trm}} \mathtt{Application(l, r)}$ to assert that the handle $\mathtt{h}$ points-to a term application (of the term pointed-to by $l$ to the term pointed-to by $r$).
Write $\mathtt{out} \mapsto \mathtt{b}$ to assert that $\mathtt{out}$ points-to the Boolean value $\mathtt{b}$.
Write $P \star Q$ for the \deffont{separating conjunction}.
Finally, write $\{ P \} C \{ Q \}$ to assert that $C$ executing in a state satisfying $P$ succeeds and produces a state satisfying $Q$.
We then have the following example \deffont{local axiom}:
\begin{gather*}
\{ h \mapsto_{\mathtt{trm}} \mathtt{Application(l, r)} \star \mathtt{out} \mapsto b \} \\
\mathtt{Term.Handle.IsApplication(h, out)} \\
\{ h \mapsto_{\mathtt{trm}} \mathtt{Application(l, r)} \star \mathtt{out} \mapsto \mathtt{True} \}
\end{gather*}
Note that the structural \deffont{frame rule} captures the fact that any system call only manipulates a defined footprint of kernel and untrusted code's memory.

\fi

\end{document}





To enforce system-wide security policies, most operating systems implement a self-contained \emph{kernel} which serves as the root of all trust within the system.
The kernel is the sole component able to directly interact with hardware, and provides services to executing user-space software, for example the abstraction of a hierarchical filesystem.
Untrusted user-space code resides outside of the kernel and interacts with it through a defined \emph{ABI}.

To enforce logical soundness, many proof-checking systems implement a self-contained \emph{kernel} which serves as the root of all trust within the system.
The kernel is the sole system component able to authenticate a proof as legitimate.
Untrusted code resides outside of the kernel and interacts with it through a defined \emph{API}.

Though ostensibly wildly different, in \emph{some} respects the goals of operating system and proof-checking kernels are the same: the maintenance of important system invariants in the face of unbounded interaction with untrusted code.
The mechanisms employed to protect these invariants, by each type of system, are different however.
For operating systems, machine-oriented notions of separation are employed, with the kernel executing at a higher prilege level than untrusted code, and cosseted by paged memory protection---hardware and privileged software work together to provide an abstract machine interface to untrusted code.
On the other hand, LCF-style proof-checking kernels are typically implemented as libraries within a \emph{meta-language}---usually an ML dialect---with invariants maintained through type abstraction and code encapsulation behind module boundaries.
Logical soundness follows from type-soundness of the meta-language.

Yet, what happens if we structure proof-checking software more like supervisory system software---such as operating systems, hypervisors, and programming language runtimes?
Now, the proof-checking kernel is not implemented as a library, but rather becomes a programming platform, exposing an abstract machine to untrusted code, in much the same way that the Linux kernel, for example, exposes an abstract machine to user-space code through its system call interface.
We are currently developing a prototype system, \emph{Supervisionary}, implemented as a WebAssembly host, to explore the consequences of this design.

One immediate consequence of Supervisionary's design is the abolition of the LCF-style meta-language.
Rather, Supervisionary's kernel is implemented in Rust---a notably \emph{unsafe} systems language.
Moreover, untrusted code which ``drives'' the Supervisionary kernel to produce an authenticated theorem need not necessarily be written in the same language that the kernel is written in: rather any language that can be compiled to code that is binary-compatible with the Supervisionary abstract machine can be used, even a mixture of them, in much the same way that Linux user-space software can be written in Haskell, Ada, or any other language that can be linked together, despite the kernel being written in C.

Note that the use of Rust to implement the Supervisionary kernel does not pose any risk to the logical soundness of the system, providing we expose a carefully designed abstract machine through the Supervisionary ABI.
The Supervisionary kernel manages various private memory spaces, or heaps, within which \emph{kernel objects} are managed.
These kernel objects correspond to the parephenalia of a typical HOL implementation---type-formers, types, term constants, terms, and theorems---but are never directly exposed to untrusted code.
Rather, kernel objects are allocated by the kernel in one of its private heaps, through ABI functions like the following:
\begin{displaymath}
\mathtt{Term.Handle.AllocateApplication(left, right, out)}
\end{displaymath}
Above, both $\mathtt{left}$ and $\mathtt{right}$ passed to the function are kernel handles, assumed to point-to allocated terms.
On the other hand, the $\mathtt{out}$ pointer points-into the heap of the code calling the function (note that the kernel can freely read from, and write to, the memory of untrusted code, given it is supervisory software).
Providing both $\mathtt{left}$ and $\mathtt{right}$ indeed point-to allocated terms, and their types match, a new kernel object corresponding to a term application is allocated, with internal pointers to the functional- and argument-terms, in the kernel's heap.
This new object is pointed-to by a freshly-generated handle, returned back to the caller via the $\mathtt{out}$ pointer.

Note that Supervisionary ABI functions do not panic, or otherwise abort, modulo bugs in the implementation of the kernel itself.
Rather, errors are signalled to calling code via a defined \emph{error code} which can be used to deduce the cause of failure: if either $\mathtt{left}$ or $\mathtt{right}$ above dangle, then the $\mathtt{DanglingHandle}$ code is returned, for example.
Note that these checks for dangling handles---which all Supervisionary ABI functions perform---ensures that the kernel heaps remain \emph{inductive}, or ``downward closed'', with nodes in the kernel object graph always pointing to previously-allocated objects at all times---a basic kernel invariant.

Post allocation, all manipulation and querying of kernel objects is performed by the kernel itself.
For example, to check if a handle points-to a $\lambda$-abstraction, untrusted code can call the following function:
\begin{displaymath}
\mathtt{Term.Handle.IsLambda(handle, out)}
\end{displaymath}
This again returns a defined error code if $\mathtt{handle}$ dangles, leaving $\mathtt{out}$ unchanged, or otherwise writing $\mathtt{true}$ or $\mathtt{false}$ to the $\mathtt{out}$ pointer as appropriate.

Unfortunately, space constraints here prevent us from providing a pr\`{e}cis of all ABI functions for allocating, querying, destructuring, and otherwise manipulating type-formers, types, term constants, and terms.
However, note that theorems are also gradually constructed in an analogous way to how terms are constructed.
For example, the HOL symmetry inference rule is exposed as:
\begin{displaymath}
\mathtt{Theorem.Handle.AllocateSym(pre, out)}
\end{displaymath}
Here, $\mathtt{pre}$ points-to an allocated theorem $\Gamma \vdash r = s$ and after successfully completing, $\mathtt{out}$ contains a handle that points-to a newly-allocated theorem $\Gamma \vdash s = r$.
Note that the heap of theorem objects must only ever grow monotonically, and a theorem object must always remain immutable once allocated by the kernel.
This immutable aspect also applies to any kernel object mentioned by any allocated theorem---terms, types, and so on: it would be decidedly \emph{inconvenient} if the meaning of the HOL truth constant were redefined, for example.
On the other hand, it seems possible that some kernel heaps could shrink, for example allocated type-formers, types, term constants, and terms, that are not referenced transitively by any allocated theorem could be garbage collected.
This is not yet implemented in Supervisionary.

Note that one consequence of this style of implementation is the ability to provide concise \emph{specifications} of Supervisionary ABI functions.
Essentially, the Supervisionary kernel is a grand exercise in pointer manipulation, and as such our ABI specifications can be expressed as Hoare Triples, using Separation Logic as our assertion language.
Writing $\mathtt{h} \mapsto_{\mathtt{trm}} \mathtt{Application(l, r)}$ to assert that the handle $\mathtt{h}$ points-to a term application (of the term pointed-to by $l$ to the term pointed-to by $r$), and writing $\mathtt{out} \mapsto \mathtt{b}$ to assert that $\mathtt{out}$ points-to the Boolean value $\mathtt{b}$, we have, for example:
\begin{gather*}
\{ h \mapsto_{\mathtt{trm}} \mathtt{Application(l, r)} \} \\
\mathtt{Term.Handle.IsApplication(h, out)} \\
\{ \mathtt{out} \mapsto \mathtt{True} \}
\end{gather*}
(Here, the triple $\{ P \} C \{ Q \}$ asserts that if the command $C$ executes in a state concordant with $P$ then the command succeeds and produces a state concordant with $Q$.)

The material presented so far is implemented in Supervisionary.
We now speculate on opportunities for future work.

First, observe that Supervisionary is not merely a rehashing of LCF, perhaps with some minor tweaks.
In particular, Supervisionary ``internalises'' theorems as kernel objects in a way that LCF does not: the latter authenticates theorems by producing an opaque object, of a particular abstract type, which in a sense``passes out'' of the kernel.
Moreover, Supervisionary behaves like a typical operating system, or programming language runtime, in that it takes a monopoly on the system's resources from the point of view of untrusted code.
To access the filesystem, or a device for example, untrusted code generally has no choice but to interact with the operating system, which gates access based on a prevailing security policy. 
Adding ABI functions to Supervisionary for filesystem access allows WebAssembly programs executing under Supervisionary to access the system's filesystem, at the cost of passing through the Supervisionary kernel.
What, then, if we force code wishing to interact with the filesystem (or any other system resource) to provide a particular \emph{theorem} to the kernel before that access is granted?
